\relax 
\citation{gdpr}
\citation{data_volume}
\citation{swarmbetterthanone}
\citation{survey_on_fed_learning}
\citation{fed_table_survey}
\citation{fed_learning}
\citation{fed_privacy}
\citation{fed_iot_2}
\citation{multi_center_fed_learning}
\citation{fed_leaderelec}
\citation{blockchain_review}
\citation{blockchain_scale}
\citation{blockchain_scale}
\@writefile{toc}{\contentsline {section}{\numberline {I}INTRODUCTION}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {II}BACKGROUND}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {II-A}Federated Learning}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {II-B}Blockchain}{1}{}\protected@file@percent }
\newlabel{bg:bc}{{II-B}{1}}
\citation{swarm_learning}
\citation{swarm_resil}
\citation{leaderelection}
\citation{swarmscalable}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-C}Swarm Learning}{2}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Diagram of different learning algorithms. Each \emph  {Node} indicates a single training machine, and each line denotes a connection between two machines, along which the model can be shared. In the swarm learning diagram, the dashed lines show that each local model is an approximation of the global model.\relax }}{2}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig_learning}{{1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Algorithm Design}{2}{}\protected@file@percent }
\newlabel{des}{{III}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-A}Design Overview}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {III-B}The Algorithm}{3}{}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces A Single Training Step - should be called repeatedly in a loop\relax }}{3}{}\protected@file@percent }
\newlabel{updatealgo}{{1}{3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Model Received Event - called when a model update is received from a remote node\relax }}{3}{}\protected@file@percent }
\newlabel{cachealgo}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-C}Blockchain-less Algorithm}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {III-D}The Training Counter}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {III-E}Combining Neighbouring Models}{4}{}\protected@file@percent }
\newlabel{mcm}{{III-E}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {III-E.1}Training Counter Filtering}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {IV}Strategy for Gathering of Results}{4}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces The different levels of dataset size and EPS that were tested\relax }}{5}{}\protected@file@percent }
\newlabel{epsparams}{{I}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Results}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {V-A}Sparsely Connected Network of Nodes}{5}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces The statistics for different density levels\relax }}{5}{}\protected@file@percent }
\newlabel{sparsedensities}{{II}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example networks of nodes generated for each density level, visualised using the tool at \emph  {https://csacademy.com/app/graph\_editor}. Each time a simulation is started, a new random network is generated for that simulation. \relax }}{6}{}\protected@file@percent }
\newlabel{densefig}{{2}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Median accuracy by training step across 5 repeats. Each node has 1000 random data samples from MNIST-F. Quartiles are not shown.\relax }}{7}{}\protected@file@percent }
\newlabel{aeg4}{{3}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Median accuracy by training step across 5 repeats. Each node has 100 random data samples from MNIST-F. Quartiles are not shown.\relax }}{7}{}\protected@file@percent }
\newlabel{aeg5}{{4}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Median accuracy by training step across 5 repeats. Each node has 25 random data samples from MNIST-F. Quartiles are not shown.\relax }}{8}{}\protected@file@percent }
\newlabel{aeg6}{{5}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {V-B}Scenario 4: Sparsely Connected Network with Class Restrictions}{8}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Median accuracy by training step across 5 repeats. Quartiles are not shown. Each node has access to a unique set of 3 classes out of 10.\relax }}{9}{}\protected@file@percent }
\newlabel{aeg9}{{6}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Comparison of SwarmAvg to Other Methods}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {VI-A}Comparison of SwarmAvg to FedAvg}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {VI-B}Comparison of SwarmAvg to SwarmBC}{9}{}\protected@file@percent }
\bibstyle{ieeetr}
\bibdata{final}
\bibcite{gdpr}{1}
\bibcite{data_volume}{2}
\bibcite{swarmbetterthanone}{3}
\bibcite{survey_on_fed_learning}{4}
\bibcite{fed_table_survey}{5}
\bibcite{fed_learning}{6}
\bibcite{fed_privacy}{7}
\bibcite{fed_iot_2}{8}
\bibcite{multi_center_fed_learning}{9}
\bibcite{fed_leaderelec}{10}
\bibcite{blockchain_review}{11}
\bibcite{blockchain_scale}{12}
\bibcite{swarm_learning}{13}
\bibcite{swarm_resil}{14}
\bibcite{leaderelection}{15}
\bibcite{swarmscalable}{16}
\@writefile{toc}{\contentsline {section}{References}{10}{}\protected@file@percent }
\gdef \@abspage@last{10}
