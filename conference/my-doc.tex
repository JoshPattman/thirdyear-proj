%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

\title{\LARGE \bf SwarmAvg: A Novel Approach to Fully Distributed Machine Learning}


\author{Josh Pattman$^{1}$% <-this % stops a space
}

\usepackage{graphicx}
\graphicspath{{./plots/}}

\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{subcaption}
\usepackage{cite}

\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Federated learning is a technique that allows a machine learning model to be trained on data distributed across multiple data islands. This approach protects privacy by keeping the data decentralized, meaning that sensitive data does not need to ever be shared. Swarm learning is a similar technique that eliminates the need for a central server, ensuring that not only the data, but also the communication, is completely decentralized. Current Swarm Learning algorithms rely on blockchain to distribute the shared global model, however this may be a poor choice for certain scenarios closely associated with swarms. In this paper, a novel swarm learning technique called SwarmAvg is presented which operates without a blockchain. The algorithm is validated against federated learning in various scenarios, and also in some situations where federated learning cannot be applied. The benefits and drawbacks of operating Swarm Learning without a blockchain are also discussed, exemplifying some interesting reasons why one might choose to use SwarmAvg over other distributed machine learning techniques.

\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}

Machine learning is becoming an exceedingly vital tool for our society to progress. However, many modern machine learning algorithms require large volumes of diverse data to achieve optimal performance. In the ideal world, this data would be stored in a single location close to a very powerful computer for training. Unfortunately, real-world data is often distributed among multiple nodes that are unable to share the data with each other or a central location, due to privacy regulations such as GDPR \cite{gdpr}. Accessing a super computer for training is also a luxury that many cannot afford. The reduction in data volume available can negatively impact the post training performance \cite{data_volume}, and the use of a slower computer means that training may not be able to be performed as fast as needed.

\section{BACKGROUND}

Machine learning is an exceedingly vital tool in modern society. Nonetheless, as the issues which machine learning endeavours to resolve become more intricate, the possibility of utilising a single centralized intelligence diminishes. One possible remedy to this problem is the distribution of both data and computation amongst multiple nodes. Transitioning from centralized approaches to distributed approaches also offers numerous advantages. For example, it has been proven mathematically that the accuracy of a distributed system surpasses that of a centralized one \cite{swarmbetterthanone}. The following sections will provide an overview of some of the state-of-the-art approaches used to distribute machine learning.


\subsection{Federated Learning}
% Introduce federated learning
Federated Learning (FL) \cite{survey_on_fed_learning} is a technique in machine learning that aims to train a single model using all available data across nodes without requiring any data to be shared among them. \\

% Intro on how fed learning works and different types
There are a multitude of published FL frameworks \cite{fed_table_survey}, each with different merits and drawbacks for certain use cases. Federated Averaging (FedAvg) \cite{fed_learning} is a commonly used yet simple framework, which splits training into iterations where three steps take place:
\begin{enumerate}
	\item A copy of the current model is sent to each node from the central server.
	\item Each node performs some training with their copy of the model and their own private data.
	\item The trained models from each node are sent back to the server to aggregate into the new server model.
\end{enumerate}
The server model is improved over time, beyond what could be achieved by simply training on a the data stored on a single node. \\

% Specify why federated learning is better than conventional learning
As it does not require data to be shared between nodes, FL is naturally beneficial for privacy sensitive tasks compared to conventional machine learning where the data is aggregated in a central location \cite{fed_privacy}. Additionally, as FL performs training on multiple nodes in parallel, it can make better use of available training resources in situations where processing power is not only distributed among multiple nodes but also limited on each node, such as Internet of Things (IoT) \cite{fed_iot_2}.

% federate distributed
FL has been adapted into several variations which eliminate the need for a single central server. One such variant is Multi-Center Federated Learning \cite{multi_center_fed_learning}, which involves multiple central servers, each connected to different clusters of nodes. Another approach is to use leader election to select a node to function as the server \cite{fed_leaderelec}. This method can improve network resilience because, if the server fails, a new server is elected.

\subsection{Blockchain} \label{bg:bc}
% Breif intro of what a blockcahin is
Blockchain technology enables a network of nodes to record transactions on a shared ledger in a fully decentralized manner \cite{blockchain_review}. In a conventional blockchain, any participating node is permitted to add a transaction to the ledger, but once a transaction is executed, it becomes immutable and irreversible. Although blockchains are primarily associated with cryptocurrency and financial transactions, any type of data, including neural network weights, can be recorded as a transaction. \\

% Disadvantages of using blockchain
When a blockchain is scaled up, it may encounter performance issues. For instance, the Bitcoin network typically processes only 7 transactions per second on average \cite{blockchain_scale}. High confirmation delay and performance inefficiency are two primary issues related to this paper when scaling up a blockchain \cite{blockchain_scale}. These issues could prove catastrophic in a system like a swarm of robots, where it is crucial to always have the latest data and optimize limited processing power.

\subsection{Swarm Learning}
% Introduce swarm learning
Swarm Learning (SL) is a subcategory of FL which operates in a completely distributed and decentralised manner. SL enables the collaboration of nodes to learn a shared global model, however in contrast to FL, a central server is never used. SL also does not use leader election, so all nodes on the network are given the same importance. \\

In SL, the model on which new training is performed is known as the global model. However, unlike FL where the global model is stored in a central location, the global model in SL does not materially exist, but is instead a concept which is agreed upon by the nodes in the network. An illustration of the different algorithms is shown in Figure \ref{fig_learning}. \\

\begin{figure}[h]
	\includegraphics[width=\linewidth]{fedvsswarm}
	\caption{Diagram of different learning algorithms. Each \emph{Node} indicates a single training machine, and each line denotes a connection between two machines, along which the model can be shared. In the swarm learning diagram, the dashed lines show that each local model is an approximation of the global model.} \label{fig_learning}
\end{figure}

One SL algorithm, referred to by this paper as SwarmBC, uses a blockchain to store the global model \cite{swarm_learning}. In this version of SL, training is performed by repeating the following steps:
\begin{enumerate}
	\item A node obtains a copy of the global model from the blockchain.
	\item The node performs some training with their copy of the model and their own private data.
	\item The updated model is merged with the latest blockchain model and sent back to the blockchain for other nodes to use.
\end{enumerate}

% Specify why swarm learning is better than conventional learning or federated learning
SL exhibits many of the same benefits of FL over conventional learning, but it also improves upon FL in some aspects. As is often the case when comparing decentralised algorithms to their centralised counterparts \cite{swarm_resil}, the absence of a central server theoretically makes SL more resilient and robust to failures than centralized FL approaches such as FedAvg. The absence of a central server in SL not only means that the system does not entirely rely on a single node, but also that it is less sensitive to disruptions in connections between nodes. In FL, if a connection between two nodes ceases to exist, the node can no longer participate in learning without some form of tunnelling. In contrast, in SL, even if a connection between two nodes is lost, the two connected nodes are still likely to be connected to other operational nodes, enabling the system to continue functioning normally. \\

The utilisation of FL with leader election effectively addresses the challenge of ensuring system robustness, as it enables any node to serve as a replacement for the server in the event of network disconnection. Nevertheless, it is important to note that a swarm of nodes is not often completely interconnected, and the connections between the nodes are often subject to changes. This dynamic and sparse network topology can present significant complexities when it comes to leader election, leading to an increase in overhead \cite{leaderelection}. The lack of a leader election process in SL makes it a more viable option in such situations. \\

Finally, a swarm of nodes can offer greater scalability compared to its centralized counterpart, particularly if agents are restricted to communicating with only their nearby neighbours \cite{swarmscalable}. This is primarily because in such cases, there is no need for all communications to travel to a single node or server that may not be able to handle the significant volume of traffic. In a swarm, where nodes are limited to a certain number of close neighbours, the size of the swarm becomes less significant, since a single node would not experience a difference between a small or large swarm, as it would have the same number of neighbours. Consequently, SL is typically more scalable than FL.


\section{Algorithm Design} \label{des}
\subsection{Design Overview}
In SL, a node is an agent responsible for facilitating the improvement of the global model. The global model is an abstract concept representing the consensus of all nodes in the network. In the proposed version of SL, referred to as SwarmAvg, each node maintains its own model, known as the local model, which is an approximation of the global model. However, in SwarmAvg, the consensus algorithm used is repeated averaging, not blockchain like in SwarmBC. This means that at the start of each training step, every node may start with a slightly different model. As training progresses and performance begins to plateau, each node's local model should not only converge towards a minima with respect to loss, but also towards each other. \\

Each node in the network possesses a confidential dataset that is not disclosed to any other nodes. In order to train the global model, nodes fit their own local model of their local dataset. In order to maintain consistency between local and global models, a combination procedure is conducted following each round of local training, which involves the integration of neighbouring nodes models into the local model. \\

SwarmAvg works by repeating the training step until training is complete. The actions in each training step for SwarmAvg are as follows:
\begin{enumerate}
	\item Fit local model to local dataset.
	\item Send local model to all neighbours.
	\item Combine neighbouring models into local model.
\end{enumerate}

Additionally, each node retains a local cache of the most recent models of its neighbouring nodes. This cache is updated each time a neighbouring node transmits its model to the node in question, instead of being updated on-demand during the combination step. This means that nodes never have to wait for other nodes to reply to them, which could mitigate issues with poor internet connections.

\subsection{The Algorithm}
The training step, found at Algorithm \ref{updatealgo}, is the section of the algorithm which runs continuously during the lifetime of a node. It takes care of training and synchronising the local model. The provided algorithm represents the logic of a single training step, meaning that it should be run in a loop that terminates once a stop condition, such as target accuracy, has been reached.

In both of the below algorithms, a capital $M$ stands for the word \emph{Model}, and $TC$ stands for the words \emph{Training Counter}. The function $\mu_e(x)$ means the element-wise $mean(x)$ where x is a list of arrays of identical lengths, and the symbol $\mu(x)$ means the $mean(x)$, where x is a list of scalars.

\begin{algorithm}[H]
	\caption{A Single Training Step} \label{updatealgo}
	\label{mainalgo}
	\begin{algorithmic}[1]
		\State \Call{Train}{localM, localData}
		\State $localTC \gets localTC + 1$
		\ForAll{$n \in neighbors$}
		\State \Call{SendTo}{$(localM, localTC)$, $n$}
		\EndFor
		
		\For{$x \in range(maxSyncWaits)$}
		\State $neighborMs \gets \emptyset$
		\State $neighborTCs \gets \emptyset$
		\ForAll{$n \in neighbors$}
		\State $M, TC \gets$ \Call{CacheLookup}{$n$}
		\If{$TC + \beta \ge localTC$}
		\State \Call{Append}{$neighborMs$, $M$}
		\State \Call{Append}{$neighborTCs$, $TC$}
		\EndIf
		\EndFor
		\If{$length_{neighborMs} \ge \gamma$}
		\State $localM \gets (1 - \alpha) * localM + \alpha * \mu_e(neighborMs)$ \label{updatelm}
		\State $localTC \gets (1 - \alpha) * localTC + \alpha * \mu(neighborTCs)$ \label{updatetc}
		\State break
		\Else
		\State \Call{Sleep}{syncWaitTime}
		\State continue
		\EndIf
		\EndFor
	\end{algorithmic}
\end{algorithm}

The model received event, which can be found at Algorithm \ref{cachealgo}, is run on the local node every time a remote node sends the local node a model update. This event takes care of updating the local model cache, to ensure the local node has the most up-to-date information. The model update sent from the remote node should contain the model and training counter of the remote node.

\begin{algorithm}[H]
	\caption{Model Received Event} \label{cachealgo}
	\textbf{Input}: $neighbour$, $neighbourM$, $neighbourTC$
	\newline
	\begin{algorithmic}[1]
		\If{\Call{InCache}{$neighbour$}}
		\State $\_, neighbourTCOld \gets$ \Call{CacheLookup}{$neighbour$}
		\If{$neighbourTC > neighbourTCOld$}
		\State \Call{SetCache}{$neighbour$, $(neighbourM, neighbourTC)$}
		\EndIf
		\Else
		\State \Call{SetCache}{$neighbour$, $(neighbourM, neighbourTC)$}
		\EndIf
	\end{algorithmic}
\end{algorithm}

\subsection{Blockchain-less Algorithm}
Whereas SwarmBC employs a blockchain as the mechanism for distributing the global model, SwarmAvg utilises a variation of averaging with its neighbours and does not use a blockchain. This decision was made due to the long transaction confirmation time of large blockchains, which could adversely affect training as nodes continuously upload their latest networks to the network. If this process were to take an excessive amount of time, each node would be training on an outdated model. \\

Furthermore, the inefficiency of blockchains with respect to performance is another reason for not using them in SwarmAvg. SwarmAvg is designed for deployment in large swarms, with each agent possibly having low processing power. If a blockchain were utilised, some of the processing power that could be devoted to training would instead be utilised for validating transactions. In scenarios where processing power is limited, it would be practical to avoid the use of blockchains.

\subsection{The Training Counter}
A vital aspect of SwarmAvg, specifically the combination step, involves evaluating the performance of a nodes local model. The conventional approach would involve testing each model using an independent test set. However, due to the inability to exchange test sets among nodes, this approach is not feasible as it would result in non-comparable scores for each model. In order to circumvent this problem, this paper presents a heuristic metric referred to as the "training counter," which serves as an approximation of the level of training for a network by estimating the number of training steps performed on a given model. \\

The training counter can be changed in one of two manners. Firstly, the counter is incremented by 1 when the local model is trained on the local dataset, indicating that an additional step of training has been performed. Following the combination step, the training counter is also updated to reflect the how the models were combined, which can be seen in Line \ref{updatetc} of Algorithm \ref{mainalgo}.

\subsection{Combining Neighbouring Models} \label{mcm}
The combination step is a crucial component of SwarmAvg. During this step, a node merges its local model with those of its neighbours, producing an updated estimate of the global model.

The method of combination used by this paper is called Averaging with Synchronisation Rate (ASR). This involves computing the average model of all neighbours, then calculating the weighted mean between that model and the local model. This is demonstrated on Line \ref{updatealgo} of Algorithm \ref{mainalgo}.

The synchronisation rate, denoted as $\alpha$, indicates the degree to which each node adjusts its local model to align with the global model. If $\alpha$ is set too low, each node's model in the network will diverge, resulting in each node becoming trapped at a local minima, an effect referred to as divergent training. On the other hand, if $\alpha$ is too high, the progress achieved by the local node will be discarded at each averaging step, which can result in slower learning. \\

This method is beneficial over simply averaging all known models, as it provides some resistance to variation in the number of neighbours of a node. When using simple averaging, the amount of change made by the local node that persists into the next training step is inversely proportionate to the number of neighbours which were combined. However, when using averaging, the amount of change made that persists will be constant, no matter how many neighbours that are present. This may increase the stability of training, especially if the situation which SwarmAvg is deployed involves a dynamic set of neighbours.

\subsection{Training Counter Filtering}
Filtering neighbours based on their training counters is also included in this algorithm. Specifically, a node may only include its neighbour models if they meet the following statement:
\[neighborTrainingCounter + \beta \ge localTrainingCounter \]
The training offset $\beta$ is the amount the training counter of a neighbour can be behind the local training counter before it is ignored. \\

A compelling reason to allow training counter filtering is the increased fault tolerance. Consider the situation where node \emph{A} has received many model updates from many nodes, one of which being node \emph{B}. However, node \emph{B} goes offline and no longer is sending model updates. Without training counter filtering, node \emph{A} will continue to combine the outdated node \emph{B} model with it's own for as long as it is training. However, if training counter filtering is enabled, after a number of training steps the outdated model \emph{B} updates will be ignored. \\

An issue with training counter filtering pertains to the presence of runaway nodes. These nodes possess a substantially higher training counter compared to all other nodes in the network, meaning that when filtering is applied, they are left with no neighbours to utilise in the combination step. Consequently, a runaway node may start to overfit on its own training data, as this is the only data it is exposed to, thereby leading to decreased local performance, as well as potential performance reductions in the rest of the network. To address this problem in SwarmAvg, each node must wait until it has obtained at least $\gamma$ viable neighbours prior to performing the combination step. Although this measure prevents individual nodes from becoming runaway nodes, groups of size $\gamma$ still have the potential to become runaway as a unit. Nevertheless, if $\gamma$ is roughly equivalent to the number of neighbours and all neighbours train at a comparable rate, the issue is minimised.

\section{Strategy for Gathering of Results}\label{strats}
The experiments were conducted through the simulation of a group of nodes on a single computer. The accuracy of each node was evaluated on an unseen test set and subsequently recorded in a file after each training step. All nodes shared the same test set. Below are the specific details of the running of each experiment:

\subsection{Chosen Metric: Accuracy}
The metric chosen for the following experiments was accuracy, due to its comprehensible nature. Despite the fact that an unbalanced dataset presents one of the significant drawbacks of using accuracy, this concern is irrelevant in the case of the chosen dataset, MNIST Fashion (MNIST-F), since it is a balanced dataset, meaning it has the same number of samples in each class. The accuracy of each node is computed after each training step using the test subset of MNIST-F, and none of the nodes are ever provided access to the test set for training.

\subsection{Number of Simulated Nodes}
The experiments were conducted using 10 nodes, not including the server in cases where FedAvg was employed. The decision of how many nodes to simulate was based on the highest node count attainable without causing inconsistencies and crashes due to resource depletion of the training machine.

\subsection{Repeated Testing for Noise Reduction}
The training process for each experiment was conducted 10 times, and the resulting accuracies of every node were recorded. To mitigate the impact of training noise on the performance graphs, the accuracy value for each time step was calculated as the median accuracy across all nodes and runs at that time step. As there were 10 nodes, this resulted in the graphs representing median of 100 nodes.

\subsection{Configuring the SwarmAvg Algorithm}
In each of the following experiments, the algorithm was configured using a specific set of parameters $\alpha \beta \gamma$. These parameters were obtained heuristically by making an initial guess, testing, and then fine-tuning them until a satisfactory outcome was reached. However, it is important to note that an exhaustive investigation into the optimal parameter configuration for a particular type of problem is not within this papers scope, meaning that it is plausible that SwarmAvg could yield better results with more precisely tuned parameters.

\subsection{Data Provided to Each Node}
The experiments evaluate the algorithm's performance using three levels of data volume per node. These levels are considerably smaller than the full MNIST-F dataset not only to increase problem difficulty, but also as the algorithm is intended for scenarios where each nodes access to data is restricted. To create a subsection of data for each node, a random sampling with replacement method was used to select the desired number of datapoints. During the initial training phase, each node performs a single sampling of its dataset, after which that nodes data subset remains constant. The three levels of data volume can be seen in TABLE \ref{epsparams}. Additionally in one of the tests, each node only had access to 3 out of the 10 possible classes. This was achieved by initially assigning each node 3 random classes which it could sample data from. Each nodes subset of classes were chosen independently of each other.

\subsection{Training Steps and Epochs}
Due to the limited size of the dataset, a single node executes more than one epoch of training in each training step. The number of epochs carried out by a node per training step will be referred to as Epochs per Step (EPS). Empirical testing has indicated that both SL and FL exhibit improved performance with higher EPS, at times surpassing the gains from increasing the number of training steps. Moreover, the utilisation of higher EPS was favoured due to its reduced training time, compared to increasing the number of training steps. The three levels of data volume with their respective EPS are shown in TABLE \ref{epsparams}.

\begin{table}[H]
	\centering
	\begin{tabular}{l|l}
		Dataset Size & EPS \\ \hline 
		1000   & 5  \\
		100   & 10  \\
		25  & 20 
	\end{tabular}
	\caption{The different dataset sizes and their corresponding EPS that were tested} \label{epsparams}
\end{table}

\subsection{Sparsely Connected Network of Nodes}
In reality, it is uncommon for each node to be linked with every other node. To simulate a more realistic scenario, a value \emph{Density} ($\rho$). When $\rho$ is set to 0, the network is minimally linked, meaning that each node has at least one indirect path to every other node, but the minimal number of connections required to accomplish this exist. When $\rho$ is set to 1, all nodes are connected to one another in a dense fashion. Since this measure may not provide a straightforward indicator of network topology, two additional metrics are provided:  Mean Minimum Hops (MMH) and Mean Connections per Node (MCPN). MMH denotes the mean minimum number of transitions required to get from one node to another in the network. MCPN denotes the average number of connections a given node possess, for a network of 10 nodes. \\

In order to conduct thorough testing on a variety of potential deployment scenarios, several different values of $\rho$ were tested for each count of data. The values that were tested, along with their corresponding MMH and MCPN, are presented in TABLE \ref{sparsedensities}. Also included in TABLE \ref{sparsedensities} is \emph{Number of Federated Learning Nodes} (NFLN), which denotes the number nodes that FL was given to approximate the number of connections a SL node would have for that value of $\rho$.

\begin{table}[H]
	\centering
	\begin{tabular}{l|l|l|l}
		$\rho$ & MMH & MCPN & NFLN \\ \hline
		1 & 1.0 & 9.0 &  10\\
		0.25    & 1.7 & 3.6 & 4 \\
		0    & 3.0 & 1.8  & 2 \\
	\end{tabular}
	\caption{The statistics for different density levels} \label{sparsedensities}
\end{table}

In order to assist the reader with visualizing the various values of $\rho$, some sample networks that were generated for each $\rho$ can be found in Figure \ref{densefig}.

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.15\textwidth}
		\centering
		\includegraphics[width=\textwidth]{sparsegraph100}
		\caption{$density=1.0$}
	\end{subfigure}
	\begin{subfigure}[b]{0.15\textwidth}
		\centering
		\includegraphics[width=\textwidth]{sparsegraph25}
		\caption{$density=0.25$}
	\end{subfigure}
	\begin{subfigure}[b]{0.15\textwidth}
		\centering
		\includegraphics[width=\textwidth]{sparsegraph0}
		\caption{$density=0.0$}
	\end{subfigure}
	\caption{Example networks of nodes generated for each $\rho$ value, visualised using the tool at \emph{https://csacademy.com/app/graph\_editor}. Each time a simulation is started, a new random network is generated for that simulation. \label{densefig}}
{}\end{figure}

\section{Results}
Tests were performed according to the methodology set out in Section \ref{strats}. Additionally, for all tested values of $\rho$, the value of $\gamma$ was set to $round_{down}(MCPN) - 1$, which ensures that each node can progress only after waiting for all but one of its neighbours. Notably, failure to reduce $\gamma$ for less dense networks would cause many of the nodes to try to wait for more neighbours than they have, which would cause delays in training.

\subsection{Test 1 - Varying $\rho$}
WRITE SOMTHING HERE INTRODUCING THIS EXPERIMENT

\begin{figure}[H]
	\center{\textbf{Accuracy by Training Step for 1000 Samples, with Varying Density}} \\
	\includegraphics[width=0.5\textwidth]{conf_sparse_ns1000}
	\caption{Median accuracy by training step across 10 repeats. Each node has 1000 random data samples from MNIST-F.}
	\label{aeg4}
\end{figure}

SHORT ANALYSE ABOVE

\begin{figure}[H] 
	\center{\textbf{Accuracy by Training Step for 100 Samples, with Varying Density}} \\
	\includegraphics[width=0.5\textwidth]{conf_sparse_ns100}
	\caption{Median accuracy by training step across 10 repeats. Each node has 100 random data samples from MNIST-F.}
	\label{aeg5}
\end{figure}

SHORT ANALYSE ABOVE

\begin{figure}[H] 
	\center{\textbf{Accuracy by Training Step for 25 Samples, with Varying Density}} \\
	\includegraphics[width=0.5\textwidth]{conf_sparse_ns25}
	\caption{Median accuracy by training step across 10 repeats. Each node has 25 random data samples from MNIST-F.}
	\label{aeg6}
\end{figure}

SHORT ANALYSE ABOVE

ANALYSE ALL GRAPHS AS ONE

\subsection{Test 2 - Varying $\rho$ with 3 Classes}
Decentralized machine learning algorithms commonly involve a scenario where each node possesses a dataset whose distribution does not align with the overall data distribution across all nodes. In order to simulate such a scenario, a situation was created where each node was given access a unique set of three out of ten classes of MNIST-F. The performance of SwarmAvg and FedAvg were tested for each $\rho$ value., with the results shown below.


\begin{figure}[H]
	\center{\textbf{Accuracy by Training Step for 1000 Samples, with Varying Density, and 3 Classes}} \\
	\includegraphics[width=0.5\textwidth]{conf_sparse_ns1000_cl3}
	\caption{Median accuracy by training step across 10 repeats. Each node has 1000 random data samples from MNIST-F.}
	\label{aeg7}
\end{figure}

SHORT ANALYSE ABOVE

\begin{figure}[H] 
	\center{\textbf{Accuracy by Training Step for 100 Samples, with Varying Density, and 3 Classes}} \\
	\includegraphics[width=0.5\textwidth]{conf_sparse_ns100_cl3}
	\caption{Median accuracy by training step across 10 repeats. Each node has 100 random data samples from MNIST-F.}
	\label{aeg8}
\end{figure}

SHORT ANALYSE ABOVE

\begin{figure}[H] 
	\center{\textbf{Accuracy by Training Step for 25 Samples, with Varying Density, and 3 Classes}} \\
	\includegraphics[width=0.5\textwidth]{conf_sparse_ns25_cl3}
	\caption{Median accuracy by training step across 10 repeats. Each node has 25 random data samples from MNIST-F.}
	\label{aeg9}
\end{figure}

SHORT ANALYSE ABOVE

ANALYSE ALL GRAPHS AS ONE

\section{Conclusion}

\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{APPENDIX}

Appendixes should appear before the acknowledgment.

\section*{ACKNOWLEDGMENT}

I would like to thank my supervisor, Dr Mohammad Soorati, for supporting and inspiring me throughout the project, and really helping me to learn a lot more about the topic of this report.\\

I would also like to thank my secondary supervisor, Dr Jo Grundy, for always being fast to respond to any questions I have had, and always being willing to help out.\\

Finally, I would like to thank my peers James Harcourt, Daniel Say, Jack Darlison, and Siobhan Tinsley for having engaging discussions with me about the direction of my project, and always providing helpful critical feedback.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

References are important to the reader; therefore, each citation must be complete and correct. If at all possible, references should be commonly available publications.



\bibliographystyle{ieeetr}
\bibliography{final}{}


\end{document}
