\documentclass[12pt,a4paper,titlepage]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{cite}


\begin{document}
	\begin{titlepage}
		\centering\Large\emph{Electronics and Computer Science Faculty of Engineering and Physical Sciences University of Southampton}
		\\[3cm]
		\centering\Large{Josh Pattman} \\
		\centering\Large{12 December 2022} \\
		\centering\huge\textbf{Investigating Optimisations Of Swarm Learning With Respect To Real World Challenges}
		\\[4cm]
		\centering\Large{Project Supervisor: Mohammad Soorati}
		\centering\Large{Second Examiner: ?}
		\\[3cm]
		\centering\Large{A project progress report submitted for the award of \textbf{Computer Science with Artificial Intelligence}}
	\end{titlepage}


	\chapter*{Abstract}
	UP TO 200 WORDS

	\tableofcontents
	
	
	\chapter{Project Goals}
	\section{Problem}
	Currently, there is more data stored around the world than ever before. However, there are also many recent regulations that prevent the data from being used by machine learning algorithms. In many cases, this is beacuse the data owners are not comfortable or able to send the data to a central server for processing and training. The result of this is that either each data owner has to train their own inferior models, or no models are trained at all due to the lack of data.
	
	In addition to this, the world also has more electronic devices than ever before. As these devices become more and more powerful, using each device to train a machine learning model on a small amount of data becomes a possibility. However, these devices will still not outperform a fast computer alone.
	
	\section{Proposed Solution}
	Swarm learning is a type of machine learning which uses multiple devices or agents to train a machine learning model. It is similar to federated learning in this repect. However, swarm learning is a completely decentralised algorithm, where the agents decide how to train. This contrasts federated learning which requires a central server to work. One of the main features of swarm learning is that data never has to be shared amongst the agents in the learning network, which is excellent for the protection of private data. For this reason, swarm learning seems to fit the problem well, but there is another issue with swarm learning: it is still a relatively new algorithm and it faces many real world challenges that have only been adressed in isolation by existing research.
	
	\section{Goals}
	\textbf{To investigate possible optimisations of the swarm learning algorithm on simple problems, whilst adding real world constraints incrementally, and eventaully arriving at a robust swarm learning algorithm that adresses many real world issues in one.}
	
	\begin{enumerate}
		\item Create a working implementation on a simple dataset of swarm learning
		\item Incrementally add real world problems to the swarm learning algorithm
		\item Mitigate the effects of the problem on the accuracy of the algorithm by implementing either novel ideas or methods from existing literature.
		\item Ensure that the end product is as reproducable as possible such that it can be re-implemented for specific use cases.
	\end{enumerate}
	\subsubsection{Problems}
	Below are some real world problems with swarm learning. This is not a comprehensive list and more problems could be researched if nescesary.
	\begin{itemize}
		\item \textbf{Unevenly distributed features/local bias} - This is where feature in the dataset are not distributed evently between agents. For instance, when classifying mnist, one agent may see more 7s and one may see more 2s.
		\item \textbf{Sparsely connected networks} - This refers to a situation where each agent does not have direct communication with every other agent, but instead can only communicate with a few neighbors.
		\item \textbf{Data transfer limits} - This is a situation where an agent may not be able to send an entrire neural network over the internet, due to connection speed.
		\item \textbf{Low processing power agents} - This situation is where agents have much lower processing power than a standard machine that one may train a model on. For example, agents may not have accsess to a GPU.
	\end{itemize}	
	
	\section{Focussing On Project Goals}
	The plan for this project went through multiple iterations before the final plan was formulated:
	\begin{enumerate}
		\item The initial plan was to \emph{control a swarm of drones to detect objects such as natural disasters or people needing help, whilst also improving accuracy of the model over time}
		\item After discussion, the plan was changed to be \emph{perform edge processing and distributed object detection on many camera perspectives of an environment to decide where disasters are happening, whilst learning to improve the model over time}
		\item Following the initial research phase, the plan was narrowed to \emph{explore ways to optimise swarm learning for distributed detection of a simple abstract object}
		\item Finally, after the second phase of research, the settled upon plan became \emph{Investigate possible optimisations of the swarm learning algorithm}. This is the current plan.
	\end{enumerate}
	The shift of focus away from object detection and towards swarm learning is mainly for two reasons:
	\begin{enumerate}
		\item The author finds the swarm learning aspect of the project to be the most interesting part, especially after researching the subject
		\item A general framework of improvements and algorithms on swarm learning is much more useful to the real world than an implementation on a simple simulation.
	\end{enumerate}

	\section{Risk Assessment}
	\subsection{Personal Issues}
	\subsubsection{Description}
	This risk entails all personal issues which cause the author to be unable to do work, such as illness.
	\subsubsection{Risk Calculations}
	\emph{Severity (1-5):} 3 \\
	\emph{Likelihood (1-5):} 3 \\
	\emph{Overall Risk (1-25):} \textbf{9}
	\subsubsection{Mitigation}
	As many sections and modules as possible from the codebase will be designed to have minimal requirements from other sections. This means that, even if the author is unable to work for a period of time, some less important sections can be skipped with minimal effect on the reset of the project.
	\subsection{Hardware Failure - Local Computer}
	\subsubsection{Description}
	This risk entails a failure on the authors local computer of any kind, such as a graphics card or storage breakage.
	\subsubsection{Risk Calculations}
	\emph{Severity (1-5):} 4 \\
	\emph{Likelihood (1-5):} 2 \\
	\emph{Overall Risk (1-25):} \textbf{8}
	\subsubsection{Mitigation}
	To mitigate storage based failures, the project will be regularly backed up to \emph{GitHub}. If a core component of the work computer breaks, the author has access to a personal laptop and the \emph{Zepler Labs}. The deep learning environment along with dependencies is backed up to the authors \emph{Google Drive} in the form of a docker image, so that switching to a new computer would be a smooth process.
	\subsection{Hardware Failure - Iridis 5}
	\subsubsection{Description}
	This risk entails a failure on the \emph{Iridis 5 Compute Cluster} which prevents it from being accessed by the author.
	\subsubsection{Risk Calculations}
	\emph{Severity (1-5):} 5 \\
	\emph{Likelihood (1-5):} 1 \\
	\emph{Overall Risk (1-25):} \textbf{5}
	\subsubsection{Mitigation}
	\emph{Iridis 5} will play a key role in this project when simulating large numbers of agents at once. However, it is possible to simulate lower numbers (around 10) agents at the same time on the authors local machine with a basic dataset. This could be a temporary solution if \emph{Iridis 5} went down for a short time. However, for a more permanent solution, funding may be acquired from the university to run the project on a cluster of \emph{AWS} servers, as the author has some experience in that field. 
	
	\chapter{Background and Literature Review}
	\section{Background Research}
	\subsection{Keras and Python}
	What i did to learn keras and python and prepare myself
	\subsection{Iridis 5}
	What i did to learn about using iridis 5 and prep
	\section{Literature Review}
	\subsection{A survey on federated learning \cite{survey_on_fed_learning}}
	This paper is a good introductory piece to the field of federated learning. It covers a wide range of topics, without going into too much detail, which was useful to direct the author into reading more specific papers. The paper also has a basic introduction to how federated learning works, and also some potential use cases for federated learning. All in all, this paper helped point the author in the right direction for further research.

	\subsection{Swarm Learning for decentralized and confidential clinical machine learning \cite{swarm_learning}}
	Despite the fact that this paper focusses on a medical use case, it is a good introductory piece to the topic of swarm learning. A theme of the paper is privacy, and how it can affect the training speed of models. The paper points out that due to privacy legislation, sharing data between hospitals is not possibly, which can mean that training machine learning models does not reach an optimal outcome. However, a solution is proposed in the form of swarm learning: effectively a decentralised form of federated learning. It is shown that swarm learning can outperform the models trained at individual hospitals without communication.
	
	The paper also gives a good high level summary of how the swarm learning algorithm works. This was particularly useful in giving the author a basic understanding of swarm learning to prepare for further research.

	\subsection {Federated learning in Robotic and Autonomous Systems \cite{fed_in_robotics}}
	\begin{itemize}
		\item Introduced to using federated learning in robotics
		\item Real world reasons that federated learning is useful in the field of robotics
		\item Horizontal/vertical federated learning
		\item Brief look at federated object detection
		\item Practical challenges of federated (model upload time, etc)
	\end{itemize}

	\subsection{Decentralized Federated Learning: A Segmented Gossip Approach \cite{gossip_learning}}
	\begin{itemize}
		\item Problem of bandwidth for federated learning
		\item Had a very cool novel idea that every step each node only needs to pull a segment of the network. This reduces bandwidth and should deffo be somthing to try
	\end{itemize}

	\subsection{Multi-Center Federated Learning \cite{multi_center_fed_learning}}
	\begin{itemize}
		\item 
	\end{itemize}
	
	\subsection{FedBN: Federated Learning On Non-IID Features via Local Batch Normalization \cite{fedbn}}
	\begin{itemize}
		\item 
	\end{itemize}

	\subsection{Personalized Federated Learning with Theoretical Guarantees: A Model-Agnostic Meta-Learning Approach \cite{model_agnostic_meta_learning}}
	\begin{itemize}
		\item 
	\end{itemize}
	
	\chapter{Report on Technical Progress}
	\section{Implementation 1 - Basic MNIST classifier}
	A simple \emph{mnist} classifier was built using \emph{Keras} in \emph{Python}. There was only one agent which trained on the dataset, and the main reason for this was to get a baseline for the swarm learning to compete against.
	\section{Implementation 2 - Simple swarm learning}
	Using \emph{Implementation 1} as a base, a swarm of agents was created. Each agent had access to the whole dataset for training. Every agent also could communicate with every other agent. The agents acted in a loop, where they would each first train for one epoch on their copy of the training set, and then would average their models weights with all of their neighbours weights. This implementation was run on the authors local computer, so could not run more than 5 agents without serious performance problems.
	
	All 5 agents did mange to reach the same level of accuracy on the test set as \emph{Implementation 1}. However, the agents took more time and total epochs to reach this accuracy.
	
	The agents seemed to reach the final accuracy in fewer training steps if the agents training loops were offset by even intervals of time. The author hypothesizes that this may be because when the agents training is synced, some of the agents may skip the just completed training when requesting updates, which can cause training epochs to effectively be lost. This effect needs further investigation.
	\section{Implementation 3 - Reduced dataset swarm learning}
	Building on \emph{Implementation 2}, this implementation was mainly focussed around reducing the amount of data each agent gets to train on. 2000 samples were selected randomly for each agent from the training set, and these never changed. When the agents were not allowed to communicate, their test accuracy almost always stayed below 90 percent. However, when the agents shared their networks, they achieved much higher test accuracies. Interestingly, the improvement in accuracy after the 90 percent point slowed down significantly.
	
	\chapter{Project Planning}
	\section{Planned Phases of the Project}
	The project is split up into a number of phases, each of which must be completed sequentially. During these phases the interim report and final report will be developed as a skeleton in parralell.
	\begin{enumerate}
		\item Research - This phase consists of finding and reading existing literature. It is at this time that the project idea is developed fully.
		\item Simple Implementation - In this phase, a proof of concept implementation will be deveolped. It will entail a simple swarm learning algorithm learning on a basic dataset, without any complex problems. This implementation will be build upon in further phases.
		\item Interim Report - This phase is focussed on filling out and finalising the interim report.
		\item Main development - In this phase, the iterative development of the swarm learning algorithm will occur. This is actually a repetition of four sub-phases:
		\begin{enumerate}
			\item Further research on real-world problem
			\item Implement real-world problem and test current solution
			\item Implement mitigations and test / evaluate
			\item Document any discoveries and evaluations of mitigations
		\end{enumerate}
		\item Final report - In this phase, the final report will be written up.
		\item Housekeeping - This is the final phase wihch is used for any extra jobs that were not able to be completed in other phases.
	\end{enumerate}
	\section{Completed Work}
	INSERT GANT CHART HERE
	\section{Remaining Work}
	INSERT GANT CHART HERE
	
	\bibliographystyle{ieeetr}
	\bibliography{interim}{}
\end{document}