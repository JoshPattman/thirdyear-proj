\chapter{Detailed Design} \label{des}
\section{Design Overview}
In SL, a node is an agent responsible for facilitating the improvement of the global model. The global model is an abstract concept representing the consensus of all nodes in the network. In the proposed version of SL, referred to as SwarmAvg, each node maintains its own model, known as the local model, which is an approximation of the global model. However, in SwarmAvg, the consensus algorithm used is repeated averaging, not blockchain like in SwarmBC. This means that at the start of each training step, every node may start with a slightly different model. As training progresses and performance begins to plateau, each node's local model should not only converge towards a minima, but also towards each other. Over time, each nodes local model better approximates the global model, and the global model becomes a better solution to the problem. \\

Each node in the network possesses a confidential dataset that is not disclosed to any other nodes. In order to train the global model, nodes fit their own local model of their local dataset. In order to maintain consistency between local and global models, a combination procedure is conducted following each round of local training, which involves the integration of neighbouring nodes models into the local model. \\

SwarmAvg works by repeating the training step until training is complete. The actions in each training step for SwarmAvg are as follows:
\begin{enumerate}
	\item Fit local model to local dataset.
	\item Send local model to all neighbours.
	\item Combine neighbouring models into local model, using one of the methods presented in Section \ref{mcm}.
\end{enumerate}

In addition, each node retains a local cache of the most recent models of its neighbouring nodes. This cache is updated each time a neighbouring node transmits its model to the node in question, instead of being updated on-demand during the combination step. The reasoning behind this decision is elaborated upon in greater detail in Section \ref{reasonforcache}.

\section{The Algorithm}
The training step, which can be found at Algorithm \ref{updatealgo}, is the section of the algorithm which runs continuously during the time which a node is running. It takes care of training and synchronising the local model. The provided code represents what happens in a single training step, meaning that it should be run in a loop that terminates once a stop condition, such as target accuracy, has been reached.

\begin{algorithm}[H]
	\caption{A Single Training Step - should be called repeatedly in a loop} \label{updatealgo}
	\begin{algorithmic}[1]
		\State \Call{Train}{localModel, localData}
		\ForAll{$n \in neighbors$}
		\State \Call{SendTo}{$(localModel, localTrainingCounter)$, $n$}
		\EndFor
		
		\For{$x \in range(maxSyncWaits)$}
		\State $neighborModels \gets \emptyset$
		\ForAll{$n \in neighbors$}
		\State $model, traningCounter \gets$ \Call{CacheLookup}{$n$}
		\If{$trainingCounter + \beta \ge localTrainingCounter$}
		\State \Call{Append}{$neighborModels$, $model$}
		\EndIf
		\EndFor
		\If{$length_{neighborModels} \ge \gamma$}
		\If{$syncronisationMethod = "AVG"$}
		\State $localModel \gets \mu(localModel \cup neighborModels)$
		\ElsIf{$syncronisationMethod = "ASR"$}
		\State $localModel \gets (1 - \alpha) * localModel + \alpha * \mu(neighborModels)$
		\EndIf
		\Else
		\State continue
		\EndIf
		\State \Call{Sleep}{syncWaitTime}
		\EndFor
	\end{algorithmic}
\end{algorithm}

The model received event, which can be found at Algorithm \ref{cachealgo}, is run on the local node every time a remote node sends the local node a model update. This event takes care of updating the local model cache, to ensure the local node has the most up-to-date information. The model update sent from the remote node should contain the model and training counter of the remote node.

\begin{algorithm}[H]
	\caption{Model Received Event - called when a model update is received from a remote node} \label{cachealgo}
	\textbf{Input}: $neighbour$, $nModel$, $nTrainingCounter$
	\newline
	\begin{algorithmic}[1]
		\If{\Call{InCache}{$neighbour$}}
		\State $\_, nTraningCounterOld \gets$ \Call{CacheLookup}{$n$}
		\If{$nTrainingCounter > nTraningCounterOld$}
		\State \Call{SetCache}{$neighbour$, $(nModel, nTrainingCounter)$}
		\EndIf
		\Else
		\State \Call{SetCache}{$neighbour$, $(nModel, nTrainingCounter)$}
		\EndIf
	\end{algorithmic}
\end{algorithm}

\section{Blockchain-less Algorithm}
SwarmBC employs a blockchain as the mechanism for distributing the global model, whereas SwarmAvg utilizes a variation of averaging with its neighbours and does not use a blockchain. This decision was made due to the long transaction confirmation time of large blockchains, which could adversely affect training as nodes continuously upload their latest networks to the network. If this process were to take an excessive amount of time, each node would be training on an outdated model. \\

Furthermore, the inefficiency of blockchains with respect to performance is another reason for not using them in SwarmAvg. SwarmAvg is designed for deployment in large swarms, with each agent possibly having low processing power. If a blockchain were utilized, some of the processing power that could be devoted to training would instead be utilized for validating transactions. In scenarios where processing power is limited, it would be practical to avoid the use of blockchains.

\section{Keeping Track of Training: The Training Counter}
A vital aspect of SwarmAvg, specifically the combination step, involves evaluating the performance of a nodes local model. The conventional approach would involve testing each model using an independent test set. However, due to the inability to exchange test sets among nodes, this approach is not feasible as it would result in non-comparable scores for each model. In order to circumvent this problem, this paper presents a heuristic metric referred to as the "training counter," which serves as an approximation of the level of training for a network by estimating the number of training steps performed on a given model. \\

The training counter can be changed in one of two manners. Firstly, the counter is incremented by 1 when the local model is trained on the local dataset, indicating that an additional step of training has been performed. Following the combination step, the training counter is also updated to reflect the combination method that was utilized. For instance, if the neighbouring models were averaged, the training counter would be updated to represent the average of all neighbouring nodes' training counters.

\section{Combining Neighbouring Models} \label{mcm}
The combination step is a crucial component of SwarmAvg. During this step, a node merges its local model with those of its neighbours, producing an updated estimate of the global model. This paper presents multiple methods for performing the combination step. \\

In the below equations, $\mu(x)$ denotes the function $mean(x)$. All models are assumed to be 1-dimensional arrays, meaning that mathematical operations such as add ($+$) and multiply ($*$) can be performed in an element-wise fashion. To achieve this constraint in the context of neural networks, a simple flattening operation is performed on the weight matrices.

\subsection{Method 1: Averaging} \label{mcm:avg}
The most rudimentary approach to combination is to compute the average model between the local model and the models of all neighbouring nodes.
\[ localModel \gets \mu(localModel \cup neighborModels) \]
This technique is utilized in FedAvg, which is the most simplistic form of FL. The benefit of this method is that it necessitates no hyper-parameters, which means that the data scientist needs to do less tuning. However, this attribute can also be viewed as a drawback, as it affords less flexibility in terms of customization for particular tasks.

\subsection{Method 2: Averaging With Synchronisation Rate}
A more complex approach to combination is to compute the average model of all neighbours, then compute the weighted average between that model and the local model.
\[ localModel \gets (1 - \alpha) * localModel + \alpha * \mu(neighborModels) \]
The synchronisation rate, denoted as $\alpha$, indicates the degree to which each node adjusts its local model to align with the global model. If $\alpha$ is set too low, each node's model in the network will diverge, resulting in each node becoming trapped at a local minima, an effect referred to as divergent training. On the other hand, if $\alpha$ is too high, the progress achieved by the local node will be discarded at each averaging step, which can result in slower learning. \\

This method is beneficial over averaging, as described in Section \ref{mcm:avg}, as it provides some resistance to variation in the number of neighbours of a node. When using averaging, the amount of change made by the local node that persists into the next training step is proportionate to the number of neighbours which were combined. However, when using averaging, the amount of change made that persists will be constant, no matter how many neighbours that are present. This may increase the stability of training, especially if the situation which SwarmAvg is deployed involves a dynamic set of neighbours.

\subsection{Ignoring Old Models: Training Counter Filtering}
A potential modification to both of the previously mentioned combination algorithms involves filtering based on the training counter. Specifically, a node may only include its neighbour models if they meet the following statement:
\[neighborTrainingCounter + \beta \ge localTrainingCounter \]
The training offset $\beta$ is the amount the training counter of a neighbour can be behind the local training counter before it is ignored. \\

A compelling reason to allow training counter filtering is the increased fault tolerance. Consider the situation where node \emph{A} has received many model updates from many nodes, one of which being node \emph{B}. However, node \emph{B} goes offline and no longer is sending model updates. Without training counter filtering, node \emph{A} will continue to combine the outdated node \emph{B} model with it's own for as long as it is training. However, if training counter filtering is enabled, after a number of training steps the outdated model \emph{B} updates will be ignored. \\

An issue with training counter filtering pertains to the presence of runaway nodes. These nodes possess a substantially higher training counter compared to all other nodes in the network, meaning that when filtering is applied, they are left with no neighbours to utilise in the combination step. Consequently, a runaway node may start to overfit on its own training data, as this is the only data it is exposed to, thereby leading to decreased local performance, as well as potential performance reductions in the rest of the network. To address this problem in SwarmAvg, each node must wait until it has obtained at least $\gamma$ viable neighbours prior to performing the combination step. Although this measure prevents individual nodes from becoming runaway nodes, groups of size $\gamma$ still have the potential to become runaway as a unit. Nevertheless, if $\gamma$ is roughly equivalent to the number of neighbours and all neighbours train at a comparable rate, the issue is minimised.

\section{Behaviour in Sparse Networks}
Given the sparsely connected nature of distributed scenarios, it is often the case that nodes only have direct connections to a small subset of their neighbours. This is a situation where FL struggles, however the author hypothesises that SwarmAvg should be able to deal with this situation.

\subsection{Method 1: Passive Convergence}
An approach to deal with a sparsely connected network is to use the swarm learning algorithm without any modifications. This approach is effective due to the use of averaging as a combination method. When a node tries to update the global model, its changes will propagate through the network slowly, over many training iterations, even to nodes that are not directly connected. This approach has the advantage of requiring no extra data transmission, resulting in significantly less data traffic compared to other methods. \\

However, this method also has certain theoretical drawbacks. Consider a scenario where the network is comprised of several sparsely connected groups of nodes, where each node in a group is densely connected to other nodes within that group. In this case, it is possible that each group may learn a distinct solution to the problem. This is inefficient because instead of functioning as a cohesive network, there are multiple smaller networks acting somewhat independently of each other, potentially leading to a decrease in overall performance.


\subsection{Method 2: Relay} \label{relay}
A solution to the aforementioned divergence of distant groups could be to relay any received model updates, meaning that as long as each node has at least one path to reach all other nodes, the network will behave as a densely connected network. This approach offers theoretical immunity to changes in network topology, but in practice, the network's performance may still decrease compared to a truly dense network due to slower communication times between non-connected nodes. \\

The main disadvantage of this approach is the drastic increase in network traffic, which in turn will lead to longer model transfer times. If the swarm learning algorithm is applied to a low power network, such as an IoT network, the increase in network traffic may not be feasible at all. This approach can also be applied to FL with the same advantages and disadvantages. For these reasons, relaying model updates will not be discussed further.
