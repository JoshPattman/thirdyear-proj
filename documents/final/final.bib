@article{survey_on_fed_learning,
	title        = {A survey on federated learning},
	author       = {Chen Zhang and Yu Xie and Hang Bai and Bin Yu and Weihong Li and Yuan Gao},
	year         = {2021},
	journal      = {Knowledge-Based Systems},
	volume       = {216},
	pages        = {106775},
	doi          = {https://doi.org/10.1016/j.knosys.2021.106775},
	issn         = {0950-7051},
	url          = {https://www.sciencedirect.com/science/article/pii/S0950705121000381},
	keywords     = {Federated learning, Privacy protection, Machine learning},
	abstract     = {Federated learning is a set-up in which multiple clients collaborate to solve machine learning problems, which is under the coordination of a central aggregator. This setting also allows the training data decentralized to ensure the data privacy of each device. Federated learning adheres to two major ideas: local computing and model transmission, which reduces some systematic privacy risks and costs brought by traditional centralized machine learning methods. The original data of the client is stored locally and cannot be exchanged or migrated. With the application of federated learning, each device uses local data for local training, then uploads the model to the server for aggregation, and finally the server sends the model update to the participants to achieve the learning goal. To provide a comprehensive survey and facilitate the potential research of this area, we systematically introduce the existing works of federated learning from five aspects: data partitioning, privacy mechanism, machine learning model, communication architecture and systems heterogeneity. Then, we sort out the current challenges and future research directions of federated learning. Finally, we summarize the characteristics of existing federated learning, and analyze the current practical application of federated learning.}
}
@article{swarm_learning,
	title        = {Swarm Learning for decentralized and confidential clinical machine learning},
	author       = {Warnat-Herresthal, Stefanie and Schultze, Hartmut and Shastry, Krishnaprasad Lingadahalli and Manamohan, Sathyanarayanan and Mukherjee, Saikat and Garg, Vishesh and Sarveswara, Ravi and H{\"a}ndler, Kristian and Pickkers, Peter and Aziz, N. Ahmad and Ktena, Sofia and Tran, Florian and Bitzer, Michael and Ossowski, Stephan and Casadei, Nicolas and Herr, Christian and Petersheim, Daniel and Behrends, Uta and Kern, Fabian and Fehlmann, Tobias and Schommers, Philipp and Lehmann, Clara and Augustin, Max and Rybniker, Jan and Altm{\"u}ller, Janine and Mishra, Neha and Bernardes, Joana P. and Kr{\"a}mer, Benjamin and Bonaguro, Lorenzo and Schulte-Schrepping, Jonas and De Domenico, Elena and Siever, Christian and Kraut, Michael and Desai, Milind and Monnet, Bruno and Saridaki, Maria and Siegel, Charles Martin and Drews, Anna and Nuesch-Germano, Melanie and Theis, Heidi and Heyckendorf, Jan and Schreiber, Stefan and Kim-Hellmuth, Sarah and Balfanz, Paul and Eggermann, Thomas and Boor, Peter and Hausmann, Ralf and Kuhn, Hannah and Isfort, Susanne and Stingl, Julia Carolin and Schmalzing, G{\"u}nther and Kuhl, Christiane K. and R{\"o}hrig, Rainer and Marx, Gernot and Uhlig, Stefan and Dahl, Edgar and M{\"u}ller-Wieland, Dirk and Dreher, Michael and Marx, Nikolaus and Nattermann, Jacob and Skowasch, Dirk and Kurth, Ingo and Keller, Andreas and Bals, Robert and N{\"u}rnberg, Peter and Rie{\ss}, Olaf and Rosenstiel, Philip and Netea, Mihai G. and Theis, Fabian and Mukherjee, Sach and Backes, Michael and Aschenbrenner, Anna C. and Ulas, Thomas and Angelov, Angel and Bartholom{\"a}us, Alexander and Becker, Anke and Bezdan, Daniela and Blumert, Conny and Bonifacio, Ezio and Bork, Peer and Boyke, Bunk and Blum, Helmut and Clavel, Thomas and Colome-Tatche, Maria and Cornberg, Markus and De La Rosa Vel{\'a}zquez, Inti Alberto and Diefenbach, Andreas and Dilthey, Alexander and Fischer, Nicole and F{\"o}rstner, Konrad and Franzenburg, S{\"o}ren and Frick, Julia-Stefanie and Gabernet, Gisela and Gagneur, Julien and Ganzenmueller, Tina and Gauder, Marie and Gei{\ss}ert, Janina and Goesmann, Alexander and G{\"o}pel, Siri and Grundhoff, Adam and Grundmann, Hajo and Hain, Torsten and Hanses, Frank and Hehr, Ute and Heimbach, Andr{\'e} and Hoeper, Marius and Horn, Friedemann and H{\"u}bschmann, Daniel and Hummel, Michael and Iftner, Thomas and Iftner, Angelika and Illig, Thomas and Janssen, Stefan and Kalinowski, J{\"o}rn and Kallies, Ren{\'e} and Kehr, Birte and Keppler, Oliver T. and Klein, Christoph and Knop, Michael and Kohlbacher, Oliver and K{\"o}hrer, Karl and Korbel, Jan and Kremsner, Peter G. and K{\"u}hnert, Denise and Landthaler, Markus and Li, Yang and Ludwig, Kerstin U. and Makarewicz, Oliwia and Marz, Manja and McHardy, Alice C. and Mertes, Christian and M{\"u}nchhoff, Maximilian and Nahnsen, Sven and N{\"o}then, Markus and Ntoumi, Francine and Overmann, J{\"o}rg and Peter, Silke and Pfeffer, Klaus and Pink, Isabell and Poetsch, Anna R. and Protzer, Ulrike and P{\"u}hler, Alfred and Rajewsky, Nikolaus and Ralser, Markus and Reiche, Kristin and Ripke, Stephan and da Rocha, Ulisses Nunes and Saliba, Antoine-Emmanuel and Sander, Leif Erik and Sawitzki, Birgit and Scheithauer, Simone and Schiffer, Philipp and Schmid-Burgk, Jonathan and Schneider, Wulf and Schulte, Eva-Christina and Sczyrba, Alexander and Sharaf, Mariam L. and Singh, Yogesh and Sonnabend, Michael and Stegle, Oliver and Stoye, Jens and Vehreschild, Janne and Velavan, Thirumalaisamy P. and Vogel, J{\"o}rg and Volland, Sonja and von Kleist, Max and Walker, Andreas and Walter, J{\"o}rn and Wieczorek, Dagmar and Winkler, Sylke and Ziebuhr, John and Breteler, Monique M. B. and Giamarellos-Bourboulis, Evangelos J. and Kox, Matthijs and Becker, Matthias and Cheran, Sorin and Woodacre, Michael S. and Goh, Eng Lim and Schultze, Joachim L. and (COVAS), COVID-19 Aachen Study and (DeCOI), Deutsche COVID-19 Omics Initiative},
	year         = {2021},
	month        = {Jun},
	day          = {01},
	journal      = {Nature},
	volume       = {594},
	number       = {7862},
	pages        = {265--270},
	doi          = {10.1038/s41586-021-03583-3},
	issn         = {1476-4687},
	url          = {https://doi.org/10.1038/s41586-021-03583-3},
	abstract     = {Fast and reliable detection of patients with severe and heterogeneous illnesses is a major goal of precision medicine1,2. Patients with leukaemia can be identified using machine learning on the basis of their blood transcriptomes3. However, there is an increasing divide between what is technically possible and what is allowed, because of privacy legislation4,5. Here, to facilitate the integration of any medical data from any data owner worldwide without violating privacy laws, we introduce Swarm Learning---a decentralized machine-learning approach that unites edge computing, blockchain-based peer-to-peer networking and coordination while maintaining confidentiality without the need for a central coordinator, thereby going beyond federated learning. To illustrate the feasibility of using Swarm Learning to develop disease classifiers using distributed data, we chose four use cases of heterogeneous diseases (COVID-19, tuberculosis, leukaemia and lung pathologies). With more than 16,400 blood transcriptomes derived from 127 clinical studies with non-uniform distributions of cases and controls and substantial study biases, as well as more than 95,000 chest X-ray images, we show that Swarm Learning classifiers outperform those developed at individual sites. In addition, Swarm Learning completely fulfils local confidentiality regulations by design. We believe that this approach will notably accelerate the introduction of precision medicine.}
}
@article{fed_in_robotics,
	title        = {Federated Learning in Robotic and Autonomous Systems},
	author       = {Yu Xianjia and Jorge Peña Queralta and Jukka Heikkonen and Tomi Westerlund},
	year         = {2021},
	journal      = {Procedia Computer Science},
	volume       = {191},
	pages        = {135--142},
	doi          = {https://doi.org/10.1016/j.procs.2021.07.041},
	issn         = {1877-0509},
	url          = {https://www.sciencedirect.com/science/article/pii/S187705092101437X},
	note         = {The 18th International Conference on Mobile Systems and Pervasive Computing (MobiSPC), The 16th International Conference on Future Networks and Communications (FNC), The 11th International Conference on Sustainable Energy Information Technology},
	keywords     = {Robotics, Cloud Robotics, Fog Robotics, Federated Learning, Federated Reinforcement Learning, Federated Edge Learning, Distributed Learning, Distributed Ledger Technologies, Edge AI},
	abstract     = {Autonomous systems are becoming inherently ubiquitous with the advancements of computing and communication solutions enabling low-latency offloading and real-time collaboration of distributed devices. Decentralized technologies with blockchain and distributed ledger technologies (DLTs) are playing a key role. At the same time, advances in deep learning (DL) have significantly raised the degree of autonomy and level of intelligence of robotic and autonomous systems. While these technological revolutions were taking place, raising concerns in terms of data security and end-user privacy has become an inescapable research consideration. Federated learning (FL) is a promising solution to privacy-preserving DL at the edge, with an inherently distributed nature by learning on isolated data islands and communicating only model updates. However, FL by itself does not provide the levels of security and robustness required by today’s standards in distributed autonomous systems. This survey covers applications of FL to autonomous robots, analyzes the role of DLT and FL for these systems, and introduces the key background concepts and considerations in current research.}
}
@misc{gossip_learning,
	title        = {Decentralized Federated Learning: A Segmented Gossip Approach},
	author       = {Hu, Chenghao and Jiang, Jingyan and Wang, Zhi},
	year         = {2019},
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.1908.07782},
	url          = {https://arxiv.org/abs/1908.07782},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Machine Learning (cs.LG), Distributed, Parallel, and Cluster Computing (cs.DC), Networking and Internet Architecture (cs.NI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@article{multi_center_fed_learning,
	title        = {Multi-Center Federated Learning},
	author       = {Ming Xie and Guodong Long and Tao Shen and Tianyi Zhou and Xianzhi Wang and Jing Jiang},
	year         = {2020},
	journal      = {CoRR},
	volume       = {abs/2005.01026},
	url          = {https://arxiv.org/abs/2005.01026},
	eprinttype   = {arXiv},
	eprint       = {2005.01026},
	timestamp    = {Mon, 11 May 2020 14:25:51 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2005-01026.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@misc{fedbn,
	title        = {FedBN: Federated Learning on Non-IID Features via Local Batch Normalization},
	author       = {Li, Xiaoxiao and Jiang, Meirui and Zhang, Xiaofei and Kamp, Michael and Dou, Qi},
	year         = {2021},
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2102.07623},
	url          = {https://arxiv.org/abs/2102.07623},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@inproceedings{model_agnostic_meta_learning,
	title        = {Personalized Federated Learning with Theoretical Guarantees: A Model-Agnostic Meta-Learning Approach},
	author       = {Fallah, Alireza and Mokhtari, Aryan and Ozdaglar, Asuman},
	year         = {2020},
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = {33},
	pages        = {3557--3568},
	url          = {https://proceedings.neurips.cc/paper/2020/file/24389bfe4fe2eba8bf9aa9203a44cdad-Paper.pdf},
	editor       = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin}
}

@article{fed_learning,
	doi = {10.48550/ARXIV.1602.05629},
	
	url = {https://arxiv.org/abs/1602.05629},
	
	author = {McMahan, H. Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and Arcas, Blaise Agüera y},
	
	keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
	
	title = {Communication-Efficient Learning of Deep Networks from Decentralized Data},
	
	publisher = {arXiv},
	
	year = {2016},
	
	copyright = {arXiv.org perpetual, non-exclusive license}
}



@article{data_volume,
	title={Secure, privacy-preserving and federated machine learning in medical imaging},
	author={Kaissis, Georgios A and Makowski, Marcus R and R{\"u}ckert, Daniel and Braren, Rickmer F},
	journal={Nature Machine Intelligence},
	volume={2},
	number={6},
	pages={305--311},
	year={2020},
	publisher={Nature Publishing Group}
}

@inproceedings{swarm_resil,
	title={Quantification and Analysis of the Resilience of Two Swarm Intelligent Algorithms.},
	author={Varughese, Joshua Cherian and Thenius, Ronald and Schmickl, Thomas and Wotawa, Franz},
	booktitle={GCAI},
	pages={148--161},
	year={2017}
}

@inproceedings{leaderelection,
	title={Leader election in sparse dynamic networks with churn},
	author={Augustine, John and Kulkarni, Tejas and Sivasubramaniam, Sumathi},
	booktitle={2015 IEEE International Parallel and Distributed Processing Symposium},
	pages={347--356},
	year={2015},
	organization={IEEE}
}


@article{fed_table_survey,
	title={A survey on federated learning systems: vision, hype and reality for data privacy and protection},
	author={Li, Qinbin and Wen, Zeyi and Wu, Zhaomin and Hu, Sixu and Wang, Naibo and Li, Yuan and Liu, Xu and He, Bingsheng},
	journal={IEEE Transactions on Knowledge and Data Engineering},
	year={2021},
	publisher={IEEE}
}


@article{fed_iot,
	title={A survey on federated learning for resource-constrained iot devices},
	author={Imteaj, Ahmed and Thakker, Urmish and Wang, Shiqiang and Li, Jian and Amini, M Hadi},
	journal={IEEE Internet of Things Journal},
	volume={9},
	number={1},
	pages={1--24},
	year={2021},
	publisher={IEEE}
}

@article{noniid_bad,
	title={Federated learning with non-iid data},
	author={Zhao, Yue and Li, Meng and Lai, Liangzhen and Suda, Naveen and Civin, Damon and Chandra, Vikas},
	journal={arXiv preprint arXiv:1806.00582},
	year={2018}
}
@inproceedings{survey_noniid,
	title={Survey of personalization techniques for federated learning},
	author={Kulkarni, Viraj and Kulkarni, Milind and Pant, Aniruddha},
	booktitle={2020 Fourth World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4)},
	pages={794--797},
	year={2020},
	organization={IEEE}
}

@article{leaderelec_car,
	title={BDFL: a byzantine-fault-tolerance decentralized federated learning method for autonomous vehicle},
	author={Chen, Jin-Hua and Chen, Min-Rong and Zeng, Guo-Qiang and Weng, Jia-Si},
	journal={IEEE Transactions on Vehicular Technology},
	volume={70},
	number={9},
	pages={8639--8652},
	year={2021},
	publisher={IEEE}
}

@inproceedings{gdpr,
	title={Machine learning \& EU data sharing practices},
	author={Kop, Mauritz},
	year={2020},
	organization={Stanford-Vienna Transatlantic Technology Law Forum, Transatlantic Antitrust~…}
}

@inproceedings{blockchain_scale,
	author = {Yang, Di and Long, Chengnian and Xu, Han and Peng, Shaoliang},
	title = {A Review on Scalability of Blockchain},
	year = {2020},
	isbn = {9781450377676},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3390566.3391665},
	doi = {10.1145/3390566.3391665},
	abstract = {As one of the key technologies of distributed ledgers, blockchain solves the trust problem in open network without relying on any trusted third party. Its decentralized feature has a broad application prospect, but still faces scalability problem. Currently, blockchain scalability bottleneck is mainly in three aspects: performance inefficiency, high confirmation delay, and function extension. For example, Bitcoin can only deal with 7 transactions per second averagely. Obviously, it cannot meet the requirement of current digital payment scenarios, nor can it be carried in other applications such as distributed storage and credit service. What's more, different blockchain systems carry different business and requirements, so scalability is the core issue of the current development of blockchain. This paper introduces the blockchain scalability related technologies from the aspects of improving efficiency and extending functionality of blockchain system, respectively. We summarize four mainstream solutions to improve the performance of blockchain system, including Sharding mechanism, directed acyclic graph based (DAG-based), off-chain payment network and cross-chain technology. In the end, we give some suggestions for further research in blockchain scalability.},
	booktitle = {Proceedings of the 2020 The 2nd International Conference on Blockchain Technology},
	pages = {1–6},
	numpages = {6},
	keywords = {Scalability, Blockchain, Performance, Review},
	location = {Hilo, HI, USA},
	series = {ICBCT'20}
}

@techreport{blockchain_review,
	doi = {10.6028/nist.ir.8202},
	
	url = {https://doi.org/10.6028%2Fnist.ir.8202},
	
	year = 2018,
	month = {oct},
	
	publisher = {National Institute of Standards and Technology},
	
	author = {Dylan Yaga and Peter Mell and Nik Roby and Karen Scarfone},
	
	title = {Blockchain technology overview}
}

@misc{xiao2017fashionmnist,
	title={Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms}, 
	author={Han Xiao and Kashif Rasul and Roland Vollgraf},
	year={2017},
	eprint={1708.07747},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@website{graphsite,
	title={Graph Editor},
	url={https://csacademy.com/app/graph_editor/},
}

@inproceedings{swarmbetterthanone,
	title={Distributed Multi-Agent Learning is More Effectively than Single-Agent},
	author={Shuya Ke, Wenqi Liu.},
	url={https://doi.org/10.21203/rs.3.rs-1070129/v1}
	year={2021},
	month={nov},
	day={11}	
}

@article{fed_privacy,
	title = {A survey on security and privacy of federated learning},
	journal = {Future Generation Computer Systems},
	volume = {115},
	pages = {619-640},
	year = {2021},
	issn = {0167-739X},
	doi = {https://doi.org/10.1016/j.future.2020.10.007},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X20329848},
	author = {Viraaji Mothukuri and Reza M. Parizi and Seyedamin Pouriyeh and Yan Huang and Ali Dehghantanha and Gautam Srivastava},
	keywords = {Artificial intelligence, Machine learning, Distributed learning, Federated learning, Federated machine learning, Security, Privacy},
	abstract = {Federated learning (FL) is a new breed of Artificial Intelligence (AI) that builds upon decentralized data and training that brings learning to the edge or directly on-device. FL is a new research area often referred to as a new dawn in AI, is in its infancy, and has not yet gained much trust in the community, mainly because of its (unknown) security and privacy implications. To advance the state of the research in this area and to realize extensive utilization of the FL approach and its mass adoption, its security and privacy concerns must be first identified, evaluated, and documented. FL is preferred in use-cases where security and privacy are the key concerns and having a clear view and understanding of risk factors enable an implementer/adopter of FL to successfully build a secure environment and gives researchers a clear vision on possible research areas. This paper aims to provide a comprehensive study concerning FL’s security and privacy aspects that can help bridge the gap between the current state of federated AI and a future in which mass adoption is possible. We present an illustrative description of approaches and various implementation styles with an examination of the current challenges in FL and establish a detailed review of security and privacy concerns that need to be considered in a thorough and clear context. Findings from our study suggest that overall there are fewer privacy-specific threats associated with FL compared to security threats. The most specific security threats currently are communication bottlenecks, poisoning, and backdoor attacks while inference-based attacks are the most critical to the privacy of FL. We conclude the paper with much needed future research directions to make FL adaptable in realistic scenarios.}
}