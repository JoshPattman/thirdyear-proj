\section{Methods}
\subsection{Metrics}
For each graph, the x axis signifies number of epochs of training, and the y axis signifies accuracy. Accuracy is calculated after the synchronisation step, by checking the number of correct predictions on an unseen test set.

\subsection{Data Collection}
For each set of parameters to the algorithm, training was repeated 5 times, and the accuracies for each node from every run were recorded. For each timestep, the accuracy was taken to be the median accuracy between all nodes across all runs at that timestep. This helped to reduce noise in the performance metrics.

\subsection{Node Counts}
All experiments were run with 10 nodes, excluding the server when using federated learning. This number was chosen as it was the highest node count that could be achieved without the training machine's resources being exhausted and crashing.

\section{Dense Network Performance}

make a graph with different convergences for different amounts of data

\section{Dense Network Performance with Node Dropout}

the same but this time dropout nodes. Try with and without filtering to show that it increases fault tolerance

\section{Sparse Network Performance}

can only test SL here (i guess you could take average number of neighbours and do fl on that too)

\section{Sparse Network Performance with Dropout}